{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMP4vUpFzxY0"
   },
   "outputs": [],
   "source": [
    "#run these first:\n",
    "\n",
    "from functools import lru_cache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import fclusterdata\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from typing_extensions import Counter\n",
    "\n",
    "\n",
    "UL=[\"A\",'B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "LL=list(map(chr, range(ord('a'), ord('z')+1)))\n",
    "DD=[\"0\",'1','2','3','4','5','6','7','8','9']\n",
    "S=list(map(chr, range(33,48)))+list(map(chr, range(58,65)))+list(map(chr, range(91,97)))+list(map(chr, range(123,127)))\n",
    "WS=[\" \"]\n",
    "\n",
    "def abstractwords(word): #this function builds and returns a list that contains a list of each value's literal character and their class abstraction. [char,abstraction]\n",
    "  wordlist=[]\n",
    "  #word=word.strip('\"') done for results purposes only for rayyan file (also done for rayyan results)\n",
    "  for char in word:\n",
    "    if char in UL:\n",
    "      wordlist.append([char,\"Ů\"])\n",
    "    elif char in LL:\n",
    "      wordlist.append([char,\"Ł\"])\n",
    "    elif char in DD:\n",
    "      wordlist.append([char,\"Đ\"])\n",
    "    elif char in S:\n",
    "      wordlist.append([char,\"Š\"])\n",
    "    elif char in WS:\n",
    "      wordlist.append([char])\n",
    "  return(wordlist)\n",
    "\n",
    "\n",
    "coverage={}\n",
    "g=[]\n",
    "\n",
    "def getpatterns(d,word,limlength,maxlen): #this function returns generator of patterns\n",
    "    #word=word.strip('\"') #added for journal name. unreadable output so removing the \" sign for both.\n",
    "    if len(word)<limlength:\n",
    "      for i in word:\n",
    "        coverage.update({word:''})\n",
    "      g.clear()\n",
    "      combinations = itertools.product(*d)\n",
    "      flat_list = [item for sublist in d for item in sublist]\n",
    "      flat_list= (''.join(flat_list))\n",
    "      for c in combinations:\n",
    "          c=''.join(c)\n",
    "          g.append(c)\n",
    "      coverage.update({word:g[:]})\n",
    "      return(g)\n",
    "    elif len(word)>limlength and len(word)<maxlen:\n",
    "      a=word.split() #splitting by words.\n",
    "      longword=[]\n",
    "      for i in a:\n",
    "        j=i\n",
    "        for char in i:\n",
    "          if char in UL:\n",
    "            j=i.replace(char,\"Ů\")\n",
    "          elif char in LL:\n",
    "            j=j.replace(char,\"Ł\")\n",
    "          elif char in DD:\n",
    "            j=j.replace(char,\"Đ\")\n",
    "          elif char in S:\n",
    "            j=j.replace(char,\"Š\")\n",
    "          #elif char in WS:  chose not to abstract white spaces because it's just one value so creating redundant patterns.\n",
    "            #j.replace(char,\"⊔\")\n",
    "        longword.append([i,j])\n",
    "      g.clear()\n",
    "      combinations = itertools.product(*longword)\n",
    "      for c in combinations:\n",
    "        c=(' '.join(c))\n",
    "        g.append(c)\n",
    "      coverage.update({word:g[:]})\n",
    "      return(g)\n",
    "\n",
    "    else:\n",
    "      verylongword=[]\n",
    "      g.clear()\n",
    "      j=word\n",
    "      for char in word:\n",
    "        if char in UL:\n",
    "          j=j.replace(char,\"Ů\")\n",
    "        elif char in LL:\n",
    "          j=j.replace(char,\"Ł\")\n",
    "        elif char in DD:\n",
    "          j=j.replace(char,\"Đ\")\n",
    "        elif char in S:\n",
    "          j=j.replace(char,\"Š\")\n",
    "      #print(word,j)\n",
    "      g.append(word)\n",
    "      g.append(j)\n",
    "      coverage.update({word:g[:]})\n",
    "      return(g)\n",
    "\n",
    "\n",
    "\n",
    "b={}\n",
    "def getdictionary(x,count_of_word): #this function checks if a pattern exists in the dictionary, and if it does not, creates a new entry. if it does exist, adds to counter.\n",
    "  for i in x:\n",
    "    counter=b.get(i,count_of_word) # in the beginning, b is an empty dict. counter checks if i, a pattern in list/dict x is in b, if it is, we assign the current freq to the counter, otherwise, we assign 1 to a new key.\n",
    "    if i in b:\n",
    "      counter=counter+count_of_word\n",
    "    b.update({i:counter})\n",
    "  return(b)\n",
    "\n",
    "def getscore(b,genlevelcostmultiplier,minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue):\n",
    "  sorted_dict = dict(sorted(b.items(), key=lambda x:x[1],reverse=True))\n",
    "  sorted_dict2=sorted_dict.items()\n",
    "  #genlevelcostmultiplier=1.2\n",
    "  for i in sorted_dict.items():\n",
    "    genlevel=0\n",
    "    for char in i[0]:\n",
    "      if char in ('ŮŁĐŠ⊔'):\n",
    "        genlevel=genlevel+1\n",
    "\n",
    "    score=((i[1])*(1/((genlevel*genlevelcostmultiplier)+1)))\n",
    "    sorted_dict.update({i[0]:score})\n",
    "  sorted_dict = dict(sorted(sorted_dict.items(), key=lambda x:x[1],reverse=True))\n",
    "  return(loopthrough(sorted_dict,minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue))\n",
    "\n",
    "\n",
    "def loopthrough(sorted_dict,minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue):\n",
    "  def get_rows(i,patternlist):\n",
    "    coverage_values=list(coverage.values())\n",
    "    subtractthis=[]\n",
    "    saveforlater=[]\n",
    "    for row in coverage_values:\n",
    "      if patternlist[i] in row:\n",
    "        subtractthis.append([x for x in row if x != patternlist[i]])\n",
    "        saveforlater.append(row[0])\n",
    "    pattern_values.update({patternlist[i]:saveforlater})\n",
    "    return subtractthis\n",
    "\n",
    "  def get_outliers(patternlist,minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue):\n",
    "    freq_cov={}\n",
    "    outlier_patterns=[]\n",
    "    dominant_patterns=[]\n",
    "    valid_values=[]\n",
    "    outlier_values=[]\n",
    "    final_patterns={}\n",
    "    final_values={}\n",
    "    accumulate=0\n",
    "    #acc_threshold=0.95\n",
    "    for i in patternlist:\n",
    "      freq_cov.update({i:b.get(i)})\n",
    "    total=sum(freq_cov.values())\n",
    "    freq_cov_2=list(freq_cov.values())\n",
    "    mincov=(np.mean(freq_cov_2)/total)*minpatmultiplier\n",
    "    for value in freq_cov.items():\n",
    "      coveragevalue=(value[1]/total)\n",
    "      if coveragevalue>mincov and accumulate<acc_threshold:\n",
    "        dominant_patterns.append(value[0])\n",
    "        accumulate=accumulate+coveragevalue\n",
    "      else:\n",
    "        outlier_patterns.append(value[0])\n",
    "      print(coveragevalue,mincov,accumulate)\n",
    "    for dom_pat in dominant_patterns:\n",
    "      valid_values.append(pattern_values.get(dom_pat))\n",
    "    for out_pat in outlier_patterns:\n",
    "      outlier_values.append(pattern_values.get(out_pat))\n",
    "    valid_values = [item for sublist in valid_values for item in sublist]\n",
    "    outlier_values= [item for sublist in outlier_values for item in sublist]\n",
    "    final_patterns.update({'dominant': dominant_patterns})\n",
    "    final_patterns.update({'outlier patterns': outlier_patterns})\n",
    "    final_values.update({'valid':valid_values})\n",
    "    final_values.update({'outliers':outlier_values})\n",
    "    return(get_distances(freq_cov,patternlist,outlier_patterns,dominant_patterns, final_values,final_patterns,lencomparison,pvalue,smallnfpvalue, smallnfnvalue))\n",
    "\n",
    "\n",
    "  def get_distances(freq_cov,patternlist,outlier_patterns,dominant_patterns,final_values, final_patterns,lencomparison,pvalue,smallnfpvalue, smallnfnvalue): #calculates distances using class-weighted measure between pairwise dominant-dominant... and dominant-outlier. performs statistical z test to determine if significant results.\n",
    "    print(freq_cov)\n",
    "    domdom=itertools.product(dominant_patterns,dominant_patterns)\n",
    "    domout=itertools.product(dominant_patterns,outlier_patterns)\n",
    "    domoutscores={}\n",
    "    domdomscores={}\n",
    "    fpposition=[]\n",
    "    fppositiondomdom=[]\n",
    "    false_positives=[]\n",
    "    false_negatives=[]\n",
    "    for i in domout:\n",
    "      if (len(i[0])<lencomparison) and (len(i[1])<lencomparison): #similarity measure length limitation\n",
    "        try:\n",
    "          domoutscores.update({i:AZWeightedLevenshtein.distance(i[0],i[1])})\n",
    "        except:\n",
    "          if len(i[0]) != len(i[0].encode()):\n",
    "            print(i,\"not ascii\")\n",
    "    for i in domdom:\n",
    "      if (len(i[0])<lencomparison) and (len(i[1])<lencomparison): #limiting pairwise distance calculation for efficiency\n",
    "        try:\n",
    "          domdomscores.update({i:AZWeightedLevenshtein.distance(i[0],i[1])})\n",
    "        except:\n",
    "          if len(i[0]) != len(i[0].encode()):\n",
    "            print(i,\"not ascii\")\n",
    "    domoutscoreslist=list(domoutscores.values())\n",
    "    domoutarr = np.array(domoutscoreslist)\n",
    "    domoutz=stats.zscore(domoutarr)\n",
    "    if len(domoutz)>15:\n",
    "      for index,i in enumerate(domoutz):\n",
    "        if i <0 and scipy.stats.norm.sf(abs(i)) <pvalue:\n",
    "          fpposition.append(index)\n",
    "      for i in fpposition:\n",
    "        if list(domoutscores.keys())[i][1] not in false_positives:\n",
    "          false_positives.append(list(domoutscores.keys())[i][1])\n",
    "    else:\n",
    "       for item in domoutscores.items():\n",
    "         if (item[1])<smallnfpvalue and item[0][1] not in false_positives:\n",
    "           false_positives.append(item[0][1])\n",
    "    domdomscoreslist=list(domdomscores.values())\n",
    "    domdomarr = np.array(domdomscoreslist)\n",
    "    domdomz=stats.zscore(domdomarr)\n",
    "    if len(domdomz)>15:\n",
    "      for index,i in enumerate(domdomz):\n",
    "       if i >0 and scipy.stats.norm.sf(abs(i)) <pvalue:\n",
    "        fppositiondomdom.append(index)\n",
    "      for i in fppositiondomdom:\n",
    "        if (freq_cov[list(domdomscores.keys())[i][0]]>freq_cov[list(domdomscores.keys())[i][1]]):\n",
    "          if list(domdomscores.keys())[i][1] not in false_negatives:\n",
    "           false_negatives.append(list(domdomscores.keys())[i][1])\n",
    "        else:\n",
    "          if list(domdomscores.keys())[i][0] not in false_negatives:\n",
    "            false_negatives.append(list(domdomscores.keys())[i][0])\n",
    "    else:\n",
    "      for item in domdomscores.items():   #this part is added in case the number of pairwise comparisons is smaller than 15, making statistical tests less valid.\n",
    "        if(item[1]>smallnfnvalue): #largest cost of substitution of one inter-class character.\n",
    "          if (freq_cov.get(item[0][0])>freq_cov.get(item[0][1])):\n",
    "            if item[0][1] not in false_negatives:\n",
    "              false_negatives.append(item[0][1])\n",
    "          else:\n",
    "            if item[0][0] not in false_negatives:\n",
    "              false_negatives.append(item[0][0])\n",
    "    fp_values=[]\n",
    "    fn_values=[]\n",
    "    for fp_pat in false_positives:\n",
    "        fp_values.append(pattern_values.get(fp_pat))\n",
    "    for fn_pat in false_negatives:\n",
    "        fn_values.append(pattern_values.get(fn_pat))\n",
    "    fp_values= [item for sublist in fp_values for item in sublist]\n",
    "    fn_values= [item for sublist in fn_values for item in sublist]\n",
    "    final_values.update({\"FP\":fp_values})\n",
    "    final_values.update({\"FN\":fn_values})\n",
    "    final_patterns.update({\"domdomscores: \": domdomscores})\n",
    "    final_patterns.update({\"domoutscores: \": domoutscores})\n",
    "    final_patterns.update({\"FP_pat\": false_positives})\n",
    "    final_patterns.update({\"FN_pat\": false_negatives})\n",
    "    df=pd.DataFrame.from_dict(final_values,orient='index').transpose()\n",
    "    print('values:',final_values, '\\npatterns',final_patterns)\n",
    "    df.to_csv('results_col.csv', index=False)\n",
    "\n",
    "  coverage_values=list(coverage.values())\n",
    "  patternlist=list(sorted_dict.keys())\n",
    "  plistset=set(patternlist)\n",
    "  pattern_values={}\n",
    "  for i in range (len(sorted_dict)):\n",
    "    if i <len(patternlist):\n",
    "      remainingrow=get_rows(i,patternlist)\n",
    "      remainingrowflat = [item for sublist in remainingrow for item in sublist]\n",
    "      for m in remainingrowflat:\n",
    "        if m in plistset:\n",
    "          patternlist.remove(m)\n",
    "          plistset.remove(m)\n",
    "    else:\n",
    "      break\n",
    "  return(get_outliers(patternlist,minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XEsokXHA0I3",
    "outputId": "afdab662-c62e-4466-a364-50b676ac041d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting strsimpy\n",
      "  Downloading strsimpy-0.2.1-py3-none-any.whl (45 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: strsimpy\n",
      "Successfully installed strsimpy-0.2.1\n"
     ]
    }
   ],
   "source": [
    "pip install -U strsimpy #MIT License Copyright (c) 2018 luozhouyang; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the Software), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8As7zb9A26-"
   },
   "outputs": [],
   "source": [
    "\n",
    "from functools import reduce\n",
    "from strsimpy.string_distance import StringDistance\n",
    "\n",
    "\n",
    "def default_insertion_cost(char):\n",
    "    return 1.0\n",
    "def default_deletion_cost(char):\n",
    "    return 1.0\n",
    "def default_substitution_cost(char_a, char_b):\n",
    "    return 1.0\n",
    "\n",
    "class AZWeightedLevenshtein(StringDistance):\n",
    "    def __init__(self,\n",
    "                 substitution_cost_fn=default_substitution_cost,\n",
    "                 insertion_cost_fn=default_insertion_cost,\n",
    "                 deletion_cost_fn=default_deletion_cost,\n",
    "                 ):\n",
    "        self.substitution_cost_fn = substitution_cost_fn\n",
    "        self.insertion_cost_fn = insertion_cost_fn\n",
    "        self.deletion_cost_fn = deletion_cost_fn\n",
    "\n",
    "    def distance(self, s0, s1):\n",
    "        if s0 is None:\n",
    "            raise TypeError(\"Argument s0 is NoneType.\")\n",
    "        if s1 is None:\n",
    "            raise TypeError(\"Argument s1 is NoneType.\")\n",
    "        if s0 == s1:\n",
    "            return 0.0\n",
    "        if len(s0) == 0:\n",
    "            return reduce(lambda cost, char: cost + self.insertion_cost_fn(char,s0), s1, 0)\n",
    "        if len(s1) == 0:\n",
    "            return reduce(lambda cost, char: cost + self.deletion_cost_fn(char,s0), s0, 0)\n",
    "\n",
    "        v0, v1 = [0.0] * (len(s1) + 1), [0.0] * (len(s1) + 1)\n",
    "        v0[0] = 0\n",
    "        for i in range(1, len(v0)):\n",
    "            v0[i] = v0[i - 1] + self.insertion_cost_fn(s1[i - 1],s0)\n",
    "\n",
    "        for i in range(len(s0)):\n",
    "            s0i = s0[i]\n",
    "            deletion_cost = self.deletion_cost_fn(s0i,s0)\n",
    "            v1[0] = v0[0] + deletion_cost\n",
    "\n",
    "            for j in range(len(s1)):\n",
    "                s1j = s1[j]\n",
    "                cost = 0\n",
    "                if s0i != s1j:\n",
    "                    cost = self.substitution_cost_fn(s0i, s1j)\n",
    "                insertion_cost = self.insertion_cost_fn(s1j,s0)\n",
    "                v1[j + 1] = min(v1[j] + insertion_cost, v0[j + 1] + deletion_cost, v0[j] + cost)\n",
    "            v0, v1 = v1, v0\n",
    "\n",
    "        return v0[len(s1)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from strsimpy.weighted_levenshtein import WeightedLevenshtein\n",
    "\n",
    "\n",
    "def insertion_cost(char,word):\n",
    "    if (word[len(word)-1] in LL or word[len(word)-1]=='Ł')  and (char in LL or char==\"Ł\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-1] in LL or word[len(word)-1]=='Ł') and (char not in LL or char !=\"Ł\"):\n",
    "      return 6\n",
    "    if (word[len(word)-1] in UL or word[len(word)-1]=='Ů') and (char in UL or char==\"Ů\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-1] in UL or word[len(word)-1]=='Ů') and (char not in UL or char !=\"Ů\"):\n",
    "      return 6\n",
    "    if (word[len(word)-1] in DD or word[len(word)-1]=='Đ') and (char in DD or char==\"Đ\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-1] in DD or word[len(word)-1]=='Đ') and (char not in DD or char !=\"Đ\"):\n",
    "      return 6\n",
    "    if (word[len(word)-1] in S or word[len(word)-1]=='Š') and (char in S or char==\"Š\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-1] in S or word[len(word)-1]=='Š') and (char not in S or char !=\"Š\"):\n",
    "      return 6\n",
    "    if (word[len(word)-1] in WS or word[len(word)-1]=='⊔') and (char in WS or char==\"⊔\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-1] in WS or word[len(word)-1]=='⊔') and (char not in WS or char !=\"⊔\"):\n",
    "      return 6\n",
    "\n",
    "def deletion_cost(char,word):\n",
    "    if (word[len(word)-2] in LL or word[len(word)-2]=='Ł')  and (char in LL or char==\"Ł\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-2] in LL or word[len(word)-2]=='Ł') and (char not in LL or char !=\"Ł\"):\n",
    "      return 6\n",
    "    if (word[len(word)-2] in UL or word[len(word)-2]=='Ů') and (char in UL or char==\"Ů\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-2] in UL or word[len(word)-2]=='Ů') and (char not in UL or char !=\"Ů\"):\n",
    "      return 6\n",
    "    if (word[len(word)-2] in DD or word[len(word)-2]=='Đ') and (char in DD or char==\"Đ\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-2] in DD or word[len(word)-2]=='Đ') and (char not in DD or char !=\"Đ\"):\n",
    "      return 6\n",
    "    if (word[len(word)-2] in S or word[len(word)-2]=='Š') and (char in S or char==\"Š\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-2] in S or word[len(word)-2]=='Š') and (char not in S or char !=\"Š\"):\n",
    "      return 6\n",
    "    if (word[len(word)-2] in WS or word[len(word)-2]=='⊔') and (char in WS or char==\"⊔\"):\n",
    "      return 1.5\n",
    "    elif (word[len(word)-2] in WS or word[len(word)-2]=='⊔') and (char not in WS or char !=\"⊔\"):\n",
    "      return 6\n",
    "\n",
    "\n",
    "def substitution_cost(char_a, char_b):\n",
    "    if (char_a == \"Ł\" and char_b in LL) or (char_a in LL and char_b ==\"Ł\"):\n",
    "        return 0.5\n",
    "    elif (char_a == \"Ł\" and char_b in UL) or (char_a in UL and char_b ==\"Ł\"):\n",
    "        return 2.5\n",
    "    elif (char_a == \"Ł\" and char_b ==\"Ů\") or (char_a ==\"Ů\" and char_b ==\"Ł\"):\n",
    "        return 2\n",
    "    elif (char_a == \"Ł\" and char_b in DD) or (char_a in DD and char_b ==\"Ł\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Ł\" and char_b ==\"Đ\") or (char_a ==\"Đ\" and char_b ==\"Ł\"):\n",
    "        return 7\n",
    "    elif (char_a == \"Ł\" and char_b in S) or (char_a in S and char_b ==\"Ł\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Ł\" and char_b ==\"Š\") or (char_a ==\"Š\" and char_b ==\"Ł\"):\n",
    "        return 7\n",
    "    elif (char_a == \"Ł\" and char_b in WS) or (char_a in WS and char_b ==\"Ł\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Ł\" and char_b ==\"⊔\") or (char_a ==\"⊔\" and char_b ==\"Ł\"):\n",
    "        return 7\n",
    "\n",
    "    if (char_a == \"Ů\" and char_b in UL) or (char_a in UL and char_b ==\"Ů\"):\n",
    "        return 0.5\n",
    "    elif (char_a == \"Ů\" and char_b in LL) or (char_a in LL and char_b ==\"Ů\"):\n",
    "        return 2.5\n",
    "    elif (char_a == \"Ů\" and char_b in DD) or (char_a in DD and char_b ==\"Ů\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Ů\" and char_b ==\"Đ\") or (char_a ==\"Đ\" and char_b ==\"Ů\"):\n",
    "        return 7\n",
    "    elif (char_a == \"Ů\" and char_b in S) or (char_a in S and char_b ==\"Ů\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Ů\" and char_b ==\"Š\") or (char_a ==\"Š\" and char_b ==\"Ů\"):\n",
    "        return 7\n",
    "    elif (char_a == \"Ů\" and char_b in WS) or (char_a in WS and char_b ==\"Ů\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Ů\" and char_b ==\"⊔\") or (char_a ==\"⊔\" and char_b ==\"Ů\"):\n",
    "        return 7\n",
    "\n",
    "    if (char_a == \"Đ\" and char_b in DD) or (char_a in DD and char_b ==\"Đ\"):\n",
    "        return 0.5\n",
    "    elif (char_a == \"Đ\" and char_b in LL) or (char_a in LL and char_b ==\"Đ\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Đ\" and char_b in UL) or (char_a in UL and char_b ==\"Đ\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Đ\" and char_b in S) or (char_a in S and char_b ==\"Đ\"):\n",
    "        return 6.5\n",
    "    elif (char_a == \"Đ\" and char_b ==\"Š\") or (char_a ==\"Š\" and char_b ==\"Đ\"):\n",
    "        return 6\n",
    "    elif (char_a == \"Đ\" and char_b in WS) or (char_a in WS and char_b ==\"Đ\"):\n",
    "        return 6.5\n",
    "    elif (char_a == \"Đ\" and char_b ==\"⊔\") or (char_a ==\"⊔\" and char_b ==\"Đ\"):\n",
    "        return 6\n",
    "\n",
    "    if (char_a == \"Š\" and char_b in S) or (char_a in S and char_b ==\"Š\"):\n",
    "        return 0.5\n",
    "    elif (char_a == \"Š\" and char_b in LL) or (char_a in LL and char_b ==\"Š\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Š\" and char_b in UL) or (char_a in UL and char_b ==\"Š\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"Š\" and char_b in DD) or (char_a in DD and char_b ==\"Š\"):\n",
    "        return 6.5\n",
    "    elif (char_a == \"Š\" and char_b in WS) or (char_a in WS and char_b ==\"Š\"):\n",
    "        return 6.5\n",
    "    elif (char_a == \"Š\" and char_b ==\"⊔\") or (char_a ==\"⊔\" and char_b ==\"Š\"):\n",
    "        return 6\n",
    "\n",
    "    if (char_a == \"⊔\" and char_b in WS) or (char_a in WS and char_b ==\"⊔\"):\n",
    "        return 0.5\n",
    "    elif (char_a == \"⊔\" and char_b in LL) or (char_a in LL and char_b ==\"⊔\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"⊔\" and char_b in UL) or (char_a in UL and char_b ==\"⊔\"):\n",
    "        return 7.5\n",
    "    elif (char_a == \"⊔\" and char_b in DD) or (char_a in DD and char_b ==\"⊔\"):\n",
    "        return 6.5\n",
    "    elif (char_a == \"⊔\" and char_b in S) or (char_a in S and char_b ==\"⊔\"):\n",
    "        return 6.5\n",
    "\n",
    "#Literals:\n",
    "    if (char_a in UL and char_b in LL) or (char_a in LL and char_b in UL):\n",
    "        return 3\n",
    "    elif (char_a in UL and char_b in DD) or (char_a in DD and char_b in UL):\n",
    "        return 8\n",
    "    elif (char_a in UL and char_b in S) or (char_a in S and char_b in UL):\n",
    "        return 8\n",
    "    elif (char_a in UL and char_b in WS) or (char_a in WS and char_b in UL):\n",
    "        return 8\n",
    "\n",
    "    if (char_a in LL and char_b in DD) or (char_a in DD and char_b in LL):\n",
    "        return 8\n",
    "    elif (char_a in LL and char_b in S) or (char_a in S and char_b in LL):\n",
    "        return 8\n",
    "    elif (char_a in LL and char_b in WS) or (char_a in WS and char_b in LL):\n",
    "        return 8\n",
    "\n",
    "    if (char_a in DD and char_b in S) or (char_a in S and char_b in DD):\n",
    "        return 7\n",
    "    elif (char_a in DD and char_b in WS) or (char_a in WS and char_b in DD):\n",
    "        return 7\n",
    "\n",
    "    if (char_a in S and char_b in WS) or (char_a in WS and char_b in S):\n",
    "        return 7\n",
    "\n",
    "    if (char_a in UL and char_b in UL) or (char_a in LL and char_b in LL) or (char_a in DD and char_b in DD) or (char_a in WS and char_b in WS) or (char_a in S and char_b in S):\n",
    "        return 0.5\n",
    "    return 1.0\n",
    "\n",
    "AZWeightedLevenshtein = AZWeightedLevenshtein(\n",
    "    substitution_cost_fn=substitution_cost,\n",
    "    insertion_cost_fn=insertion_cost,\n",
    "    deletion_cost_fn=deletion_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6p9TvQ3BYg5"
   },
   "outputs": [],
   "source": [
    "def main(limlength,maxlen,genlevelcostmultiplier, minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue):\n",
    "  df = pd.read_csv(r'dirty_beers.csv',sep=',')\n",
    "  df = df.astype(str)\n",
    "  testlist=pd.Series.to_dict((df['id'].value_counts()))\n",
    "  testlist\n",
    "\n",
    "  b.clear()\n",
    "  g.clear()\n",
    "  coverage.clear()\n",
    "\n",
    "  for word in testlist.items():\n",
    "    wordlist=abstractwords(word[0])\n",
    "    patterns=getpatterns(wordlist,word[0],limlength,maxlen)\n",
    "    getdict=getdictionary(patterns,word[1])\n",
    "  print(\"# of total patterns:\",len(b))\n",
    "  final=getscore(b,genlevelcostmultiplier,minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_shkuaCJ7qp",
    "outputId": "ef67d4f4-8a5a-4633-e615-dfaa29d8f82b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would you like to use default values? (Y/N)N\n",
      "limlength= (default value is 15)15\n",
      "maxlen= (default value is 40)4\n",
      "genlevelcostmultiplier= (default value is 1.2)1.2\n",
      "minpatmultiplier= (default value is 0.7)0.7\n",
      "acc_threshold= (default value is 0.95).95\n",
      "lencomparison= (default value is 20)20\n",
      "pvalue= (default value is 0.05).05\n",
      "smallnfpvalue= (default value is 1.5)1.5\n",
      "smallnfnvalue= (default value is 8)8\n",
      "# of total patterns: 4652\n",
      "0.6821576763485477 0.175 0.6821576763485477\n",
      "0.27883817427385893 0.175 0.9609958506224067\n",
      "0.03609958506224066 0.175 0.9609958506224067\n",
      "0.002904564315352697 0.175 0.9609958506224067\n",
      "{'ĐĐĐĐ': 1644, 'ĐĐĐ': 672, 'ĐĐ': 87, 'Đ': 7}\n",
      "values: {'valid': ['1436', '1175', '1065', '1908', '1946', '1961', '1684', '1268', '1805', '1048', '1043', '1166', '1328', '1087', '1532', '1533', '1931', '1054', '2635', '1404', '1403', '1402', '2312', '1636', '1518', '1384', '1797', '1437', '1791', '1540', '1491', '1335', '1053', '1055', '1930', '1056', '2238', '2144', '2175', '2168', '1956', '1794', '2633', '2632', '2631', '2630', '2629', '2628', '1062', '1061', '1060', '1720', '1430', '1059', '1058', '1828', '1487', '1486', '1485', '1394', '1381', '1431', '1721', '2333', '2331', '1669', '1668', '2247', '2071', '2070', '2069', '2192', '1130', '1129', '1081', '2335', '2334', '1530', '1529', '1167', '1883', '1528', '1527', '1526', '2113', '2112', '2302', '1859', '1252', '1796', '1790', '1752', '1751', '1750', '1444', '2002', '1764', '1102', '1101', '1100', '1099', '1098', '1330', '2074', '1724', '1280', '1860', '1577', '1103', '1877', '1575', '1878', '1852', '1851', '2307', '2580', '1807', '1180', '1179', '1771', '1654', '2579', '2373', '2049', '2048', '1880', '1879', '1576', '2304', '2559', '1995', '1329', '1299', '1073', '1072', '1071', '1392', '1934', '2063', '2249', '2073', '2053', '1842', '1841', '1782', '1552', '1479', '1478', '1370', '1868', '1867', '1865', '1864', '2599', '1935', '1992', '1993', '2031', '2030', '2269', '2229', '2370', '2211', '1861', '1718', '1290', '1091', '1086', '1021', '2132', '1760', '1759', '1589', '1457', '1191', '2336', '2553', '1909', '2360', '1463', '1462', '1461', '2516', '2515', '2514', '2513', '2576', '1133', '2452', '2451', '1075', '1538', '1374', '2512', '1467', '1375', '1373', '2087', '2414', '1581', '1176', '1006', '1005', '1258', '1264', '1190', '1578', '1429', '1271', '1237', '1236', '1047', '1985', '2197', '2120', '1234', '1233', '1232', '1231', '1831', '1359', '1135', '1986', '1984', '1917', '2666', '2663', '2662', '2535', '2534', '2533', '2532', '2531', '2530', '2529', '2528', '1612', '1611', '1273', '2664', '2667', '2186', '2668', '2185', '2184', '2178', '2177', '2176', '1508', '1507', '1506', '1325', '2093', '1814', '2268', '2308', '2583', '2581', '1309', '1308', '1571', '1204', '1122', '2033', '2032', '2311', '1153', '2582', '2584', '1516', '1168', '1832', '1688', '1687', '1686', '2434', '2332', '2330', '2329', '2327', '2326', '1926', '1924', '1090', '1475', '1008', '2454', '2209', '1600', '1484', '1356', '1355', '1334', '1674', '1673', '1672', '1671', '1670', '1262', '1783', '1717', '1716', '1624', '1625', '1626', '1124', '2133', '1994', '1816', '1815', '1126', '1125', '1813', '1628', '1113', '1884', '1272', '1080', '1690', '1417', '1586', '1707', '1536', '1737', '1705', '1148', '1147', '1146', '1145', '1758', '1757', '2475', '2230', '1987', '1978', '1975', '1307', '1306', '1305', '1304', '2692', '2691', '2690', '2689', '2688', '2687', '1854', '1227', '1226', '1621', '1622', '1811', '2043', '2272', '1582', '1114', '2042', '2041', '2050', '1265', '1537', '2441', '1459', '1476', '2236', '2159', '2157', '2156', '2154', '1495', '1494', '1493', '1460', '2442', '2273', '2361', '2359', '2358', '2282', '2281', '2280', '2279', '2278', '2277', '2276', '2275', '2274', '1492', '1598', '2345', '2224', '1775', '1291', '1093', '1051', '1907', '1906', '1756', '1617', '1052', '1046', '2413', '2237', '2208', '1952', '1391', '1683', '2265', '1856', '1027', '1026', '1938', '1937', '1936', '2445', '2444', '2203', '1510', '1509', '2458', '2623', '2622', '2621', '1817', '1449', '2321', '1755', '1754', '1428', '2588', '2212', '1041', '2037', '1285', '1189', '1171', '1170', '1169', '2310', '2100', '1925', '1723', '1212', '1097', '1089', '1040', '1042', '2235', '1121', '1661', '1660', '1659', '1438', '1173', '2497', '2246', '1630', '1284', '1222', '1889', '2601', '2155', '1982', '1939', '1082', '2119', '2118', '2117', '2116', '1916', '1915', '1914', '1810', '1111', '2447', '2614', '2448', '1433', '1432', '2640', '1200', '1199', '1198', '1276', '1732', '2347', '1781', '1780', '1779', '2421', '2319', '2317', '2316', '1913', '1912', '2617', '2616', '2615', '1277', '1278', '2638', '1037', '1197', '1945', '1079', '1748', '1747', '2594', '2035', '2034', '1562', '1561', '1749', '2455', '1088', '1362', '2571', '1498', '1838', '1837', '1836', '1619', '1618', '1364', '2253', '2570', '2572', '1195', '2573', '1542', '1312', '1645', '1551', '1550', '2364', '2348', '2344', '2343', '2342', '2341', '2340', '1318', '1194', '2372', '2306', '1697', '2194', '1514', '1513', '1512', '1511', '1345', '1316', '1045', '1035', '2417', '1468', '1676', '2149', '2148', '2147', '2146', '2047', '1470', '1469', '2627', '2626', '1069', '2356', '2439', '2564', '2562', '2561', '2560', '1932', '1853', '1315', '2563', '2565', '2221', '1950', '2367', '1704', '1703', '2507', '2506', '2190', '1951', '1826', '1825', '1846', '1845', '1844', '1843', '1418', '1038', '1030', '1029', '2450', '2223', '2222', '1488', '1603', '1729', '2245', '1824', '1823', '1682', '1681', '1680', '1679', '2244', '1730', '1378', '1377', '1376', '2411', '1770', '1769', '1009', '1017', '1123', '2407', '2406', '2405', '2234', '1606', '1211', '1363', '1192', '1013', '1792', '1609', '2537', '2536', '2305', '1588', '1798', '1063', '1970', '2024', '1283', '1282', '2362', '2346', '2320', '2297', '2296', '1745', '1120', '1118', '1117', '2387', '2267', '1740', '1969', '1971', '1655', '1972', '1596', '1595', '1482', '1447', '1425', '1424', '1298', '1181', '1160', '1152', '1151', '1150', '1076', '1297', '1521', '1708', '1416', '1415', '2250', '1768', '1767', '1766', '1765', '2368', '1539', '1302', '1942', '1519', '1477', '1503', '1466', '1245', '1324', '1323', '1078', '1077', '2474', '2239', '1919', '1918', '1388', '1387', '1386', '1385', '1020', '1591', '1608', '1696', '1905', '1338', '1295', '2353', '1962', '2574', '2479', '2443', '2266', '2090', '1728', '1497', '1011', '1128', '1049', '1127', '1314', '2164', '1347', '2084', '2083', '2082', '2081', '2001', '2000', '1999', '1996', '1948', '1656', '1599', '1420', '1389', '1367', '1366', '1207', '1206', '2543', '2409', '2551', '1710', '1709', '1229', '1164', '2575', '2555', '1736', '1196', '2568', '1554', '1238', '1739', '1112', '1239', '1242', '1241', '1240', '2085', '2215', '1010', '1819', '1633', '1632', '1587', '2242', '1544', '1205', '2386', '2366', '1634', '1820', '2605', '1821', '2486', '2271', '2206', '2136', '2135', '2134', '2109', '2365', '2270', '2228', '2151', '1983', '1631', '1344', '1410', '2369', '2233', '2232', '2231', '2352', '2549', '2473', '2415', '1225', '2150', '2122', '2121', '2115', '1450', '1357', '2036', '2504', '2499', '2498', '2481', '2476', '2467', '2466', '2465', '2433', '2418', '2416', '2382', '2381', '2290', '2241', '2240', '2500', '2541', '2101', '2542', '1522', '1802', '1801', '1800', '1799', '2619', '2468', '2637', '2636', '2598', '2597', '2548', '2137', '2092', '1095', '1266', '1136', '1044', '1033', '1031', '1178', '1267', '2091', '1352', '2086', '2023', '2006', '1997', '1977', '1976', '1974', '1973', '1959', '1958', '1949', '1947', '1785', '1651', '1443', '2204', '2167', '1607', '1597', '1569', '1568', '1188', '1891', '1890', '2422', '1727', '1288', '2487', '1372', '1371', '1812', '1547', '1546', '1545', '1408', '2490', '2489', '2488', '1614', '1613', '1549', '1548', '1349', '1310', '1281', '1144', '1143', '1395', '2596', '2300', '2299', '2298', '2107', '1573', '1289', '1427', '1601', '1629', '1023', '1517', '1500', '1421', '1360', '1184', '1183', '1830', '2062', '1096', '2456', '2094', '1941', '1940', '1439', '1465', '1464', '1744', '1743', '1742', '1719', '1882', '1881', '2255', '2106', '1928', '1927', '2227', '2226', '2225', '1954', '1910', '1177', '2446', '2600', '1933', '2018', '2017', '2016', '2080', '2079', '2380', '2379', '2354', '2440', '1342', '1341', '2349', '2014', '2013', '2019', '2055', '2210', '2056', '2052', '1584', '1182', '1050', '1219', '1218', '2377', '1839', '1248', '1247', '1649', '1648', '1647', '1646', '2057', '2064', '2065', '2066', '2552', '2124', '2123', '2608', '2607', '2606', '2478', '2471', '2470', '2464', '2160', '2158', '2072', '2054', '2196', '2125', '1627', '2067', '1279', '2257', '2256', '2068', '2252', '2657', '2656', '2655', '2654', '2653', '2652', '2214', '1419', '2213', '1442', '2315', '1808', '1012', '1473', '2592', '2578', '2577', '2103', '2102', '2291', '1818', '1738', '1563', '1520', '1350', '1327', '1326', '1221', '1217', '1474', '1149', '2678', '2677', '2676', '2675', '2674', '1594', '1162', '1137', '2403', '2402', '2401', '1921', '1920', '2501', '1535', '1025', '1333', '1332', '1172', '1322', '1640', '1639', '1638', '1580', '2509', '2337', '1294', '1293', '1292', '2207', '2040', '2039', '2511', '2510', '2679', '2680', '2681', '1593', '1036', '1024', '1592', '1502', '2682', '2169', '2264', '2263', '2262', '2261', '2260', '2259', '2258', '2131', '2099', '2098', '2097', '1980', '1979', '2318', '2170', '2519', '1583', '1165', '2540', '2539', '2686', '2685', '2684', '2683', '2216', '2217', '2287', '2518', '2517', '2545', '2544', '2324', '2288', '2286', '2218', '2285', '1870', '2603', '2602', '2220', '2219', '2503', '2502', '1001', '2469', '2586', '2585', '1714', '1713', '1712', '1711', '1456', '2639', '1002', '2496', '1003', '1902', '1901', '1261', '1253', '1900', '1317', '1158', '1157', '1156', '1155', '1154', '2104', '1762', '1422', '1067', '2096', '2095', '2485', '2484', '2449', '2634', '2153', '1953', '1496', '1481', '1480', '1564', '1541', '1321', '1320', '1319', '1303', '1847', '1848', '1849', '1441', '1257', '1256', '1255', '2508', '1413', '1850', '1411', '2620', '2412', '1898', '1897', '1896', '2410', '2556', '2495', '2058', '1483', '1426', '1132', '1131', '1876', '1875', '2593', '2105', '1401', '1400', '1019', '1228', '2557', '1579', '1409', '2589', '2546', '1620', '1018', '1776', '1644', '1643', '1806', '2435', '2423', '2420', '2419', '2494', '2325', '2022', '1989', '1988', '1955', '2558', '2188', '2618', '2005', '1343', '2404', '2323', '2189', '2187', '1209', '1966', '1965', '1964', '1963', '1855', '1778', '2012', '2011', '2010', '2007', '2339', '1857', '1440', '1753', '1448', '1134', '1066', '2026', '1361', '1016', '1015', '1570', '2138', '1331', '2139', '2313', '2461', '2044', '1567', '1505', '1186', '1185', '2375', '2143', '2142', '2141', '2140', '1677', '1270', '2179', '1894', '1893', '1351', '1346', '2295', '2294', '1615', '1895', '2180', '2059', '2181', '1653', '1558', '1380', '1379', '1340', '1313', '2183', '2182', '2314', '1106', '2129', '2127', '2126', '2303', '1990', '1702', '1701', '1700', '1699', '1269', '1109', '1108', '1000', '2205', '2198', '2457', '2202', '2201', '1829', '1383', '1574', '1446', '1275', '1244', '1064', '1028', '1604', '1922', '1923', '2648', '2650', '2649', '2647', '2646', '2645', '2644', '2643', '2642', '1068', '1678', '1572', '1348', '1193', '1187', '1235', '1458', '2595', '2480', '1525', '1524', '1523', '1254', '2060', '2163', '2162', '2374', '1560', '1557', '2472', '2547', '2493', '2492', '2491', '2108', '1397', '1396', '1675', '1249', '1445', '1741', '1637', '1667', '2436', '1706', '1666', '1665', '2460', '2459', '1274', '1220', '1070', '2408', '1652', '2482', '2399', '2398', '2397', '2396', '2395', '2394', '2393', '2392', '2391', '2390', '2389', '2388', '2200', '2199', '2193', '2400', '2483', '2357', '1835', '1834', '1833', '2195', '1605', '1543', '1390', '1354', '1353', '1501', '1004', '1398', '1085', '2376', '1784', '2673', '2672', '2671', '2670', '2669', '1405', '1793', '2453', '2363', '1774', '2038', '2609', '1903', '2385', '2384', '2383', '1251', '1250', '1691', '1904', '1555', '1115', '2350', '2301', '2587', '2009', '2166', '1203', '1202', '1161', '1886', '1885', '1213', '1159', '1944', '1943', '1210', '2550', '1827', '2251', '2025', '2371', '2078', '1809', '1263', '1092', '1224', '1623', '1735', '1734', '1746', '2505', '2021', '1246', '1685', '1590', '1382', '1110', '1014', '1642', '2015', '1888', '1887', '2051', '1201', '1773', '1795', '1311', '1763', '1786', '1365', '1094', '1772', '1393', '1407', '1406', '2438', '2437', '2338', '1787', '1726', '1725', '1695', '1694', '1693', '1692', '1369', '1243', '1142', '1141', '1140', '1139', '1138', '2061', '2028', '2293', '1105', '1104', '2145', '1804', '1602', '1301', '1057', '1789', '1788', '2029', '2351', '1650', '1337', '1336', '2538', '2355', '1689', '1163', '1107', '1039', '2477', '2612', '2610', '1657', '2309', '1635', '1616', '1585', '2428', '2427', '2425', '2424', '1998', '1556', '2611', '2613', '1515', '1872', '2322', '2661', '2660', '2659', '2658', '2625', '1565', '1223', '1874', '1873', '1208', '2527', '2526', '2525', '2076', '2075', '2426', '2045', '1960', '1777', '1698', '1641', '1490', '1489', '1399', '1296', '1034', '2077', '1658', '2254', '1116', '2524', '2523', '2522', '2521', '2520', '1174', '1259', '1300', '1260', '1214', '1566', '2008', '1434', '2088', '1455', '1454', '1453', '1452', '1451', '2191', '1731', '1022', '2289', '2027', '1929', '2089', '1435', '1803', '1722', '2004', '2003', '2292', '1504', '2604', '2432', '2431', '2430', '2429', '1967', '2283', '2248', '1287', '1286', '1858', '2591', '2590', '1968', '2554', '2567', '2566', '1899', '2111', '2110', '2172', '2171', '1911', '1610', '2284', '2624', '1981', '1664', '1663', '1662', '1733', '2569', '2463', '2462', '1957', '927', '697', '696', '695', '694', '890', '805', '804', '803', '787', '786', '785', '745', '744', '743', '742', '741', '734', '733', '775', '521', '847', '603', '602', '601', '600', '900', '891', '128', '999', '509', '508', '955', '933', '892', '828', '806', '755', '754', '726', '720', '661', '585', '565', '391', '388', '992', '993', '846', '479', '899', '363', '158', '852', '850', '839', '777', '764', '317', '286', '285', '124', '883', '882', '399', '830', '938', '715', '130', '188', '335', '711', '709', '708', '706', '220', '219', '609', '418', '417', '416', '415', '414', '710', '945', '583', '339', '636', '150', '713', '712', '690', '547', '435', '313', '133', '453', '686', '960', '959', '958', '957', '956', '773', '365', '273', '174', '587', '586', '434', '725', '700', '355', '125', '962', '961', '573', '574', '845', '360', '511', '952', '748', '578', '564', '563', '115', '885', '884', '757', '568', '320', '747', '746', '654', '541', '109', '486', '485', '484', '913', '646', '165', '915', '914', '932', '902', '645', '644', '337', '336', '314', '776', '172', '171', '327', '719', '718', '131', '862', '699', '421', '420', '580', '403', '316', '315', '132', '326', '625', '717', '768', '419', '408', '594', '114', '113', '433', '641', '736', '494', '495', '121', '951', '950', '949', '948', '529', '974', '861', '642', '560', '519', '518', '505', '482', '451', '122', '827', '589', '973', '765', '676', '595', '537', '412', '105', '104', '103', '102', '101', '936', '544', '379', '963', '971', '740', '430', '398', '366', '334', '162', '652', '576', '575', '822', '928', '807', '620', '145', '826', '825', '813', '324', '323', '762', '761', '907', '906', '683', '614', '466', '444', '345', '877', '606', '543', '347', '346', '829', '582', '382', '381', '908', '619', '618', '780', '912', '894', '166', '617', '407', '406', '926', '393', '774', '386', '402', '995', '879', '815', '918', '917', '738', '975', '814', '727', '588', '967', '599', '307', '305', '304', '217', '778', '630', '629', '628', '525', '512', '425', '424', '423', '422', '212', '426', '400', '161', '160', '934', '923', '874', '739', '698', '660', '651', '584', '532', '526', '394', '213', '663', '662', '623', '622', '362', '361', '329', '855', '445', '369', '368', '856', '853', '691', '555', '763', '922', '925', '637', '953', '138', '139', '816', '140', '772', '684', '650', '456', '357', '141', '471', '472', '397', '193', '909', '873', '860', '677', '671', '670', '669', '627', '387', '385', '384', '470', '692', '665', '344', '577', '513', '667', '939', '888', '886', '612', '611', '119', '808', '998', '997', '996', '931', '798', '633', '473', '530', '638', '507', '480', '427', '782', '840', '180', '784', '783', '921', '567', '668', '920', '919', '648', '756', '566', '328', '538', '504', '383', '792', '791', '790', '789', '788', '870', '869', '868', '867', '793', '794', '878', '170', '169', '937', '942', '837', '753', '811', '572', '390', '550', '429', '428', '597', '596', '980', '979', '735', '413', '523', '367', '410', '409', '976', '876', '802', '801', '800', '799', '797', '796', '531', '432', '353', '321', '173', '866', '431', '516', '515', '514', '972', '978', '643', '632', '767', '766', '579', '168', '159', '986', '985', '705', '702', '966', '965', '704', '534', '528', '527', '343', '342', '341', '340', '146', '108', '107', '106', '533', '183', '182', '707', '910', '954', '849', '352', '149', '148', '984', '693', '631', '548', '990', '989', '988', '904', '824', '616', '889', '770', '769', '610', '192', '126', '506', '181', '189', '143', '930', '649', '639', '626', '615', '142', '476', '190', '477', '312', '311', '309', '308', '581', '478', '455', '442', '441', '865', '864', '863', '672', '655', '540', '539', '517', '371', '440', '439', '436', '389', '164', '404', '724', '497', '496', '465', '464', '463', '349', '348', '760', '759', '758', '666', '687', '469', '468', '467', '779', '364', '664', '392', '195', '475', '474', '781', '590', '688', '689', '499', '498', '502', '501', '916', '658', '559', '558', '553', '823', '653', '729', '728', '549', '946', '943', '947', '929', '851', '186', '185', '184', '964', '110', '749', '881', '880', '872', '871', '457', '911', '680', '395', '673', '977', '446', '447', '924', '731', '730', '647', '944', '524', '450', '449', '448', '545', '657', '656', '359', '893', '751', '120', '546', '569', '571', '570', '970', '969', '968', '542', '272', '271', '681', '356', '613', '716', '737', '129', '659', '685', '556', '940', '358', '179', '178', '674', '562', '552', '319', '318', '991', '750', '994', '901', '875', '858', '857', '895', '682', '112', '640', '520', '608', '607', '983', '982', '981', '809', '941', '935', '481', '351', '350'], 'outliers': ['97', '82', '64', '33', '32', '31', '75', '74', '73', '72', '71', '43', '42', '41', '40', '39', '94', '98', '80', '79', '25', '24', '23', '22', '21', '20', '70', '69', '68', '67', '30', '53', '55', '54', '16', '19', '18', '17', '15', '14', '13', '12', '92', '91', '90', '46', '45', '44', '83', '89', '88', '81', '63', '62', '61', '26', '66', '65', '29', '28', '27', '52', '51', '50', '49', '38', '37', '36', '78', '77', '76', '11', '10', '48', '47', '35', '34', '96', '87', '86', '85', '60', '59', '58', '57', '56', '84', '1', '4', '5', '6', '7', '8', '9'], 'FP': [], 'FN': []} \n",
      "patterns {'dominant': ['ĐĐĐĐ', 'ĐĐĐ'], 'outlier patterns': ['ĐĐ', 'Đ'], 'domdomscores: ': {('ĐĐĐĐ', 'ĐĐĐĐ'): 0.0, ('ĐĐĐĐ', 'ĐĐĐ'): 1.5, ('ĐĐĐ', 'ĐĐĐĐ'): 1.5, ('ĐĐĐ', 'ĐĐĐ'): 0.0}, 'domoutscores: ': {('ĐĐĐĐ', 'ĐĐ'): 3.0, ('ĐĐĐĐ', 'Đ'): 4.5, ('ĐĐĐ', 'ĐĐ'): 1.5, ('ĐĐĐ', 'Đ'): 3.0}, 'FP_pat': [], 'FN_pat': []}\n"
     ]
    }
   ],
   "source": [
    "default=(input)(\"would you like to use default values? (Y/N)\")\n",
    "if default=='Y':\n",
    "   limlength=15\n",
    "   maxlen=40\n",
    "   genlevelcostmultiplier=1.2\n",
    "   minpatmultiplier=0.7\n",
    "   acc_threshold=0.95\n",
    "   lencomparison=20\n",
    "   pvalue=0.05\n",
    "   smallnfpvalue=1.5\n",
    "   smallnfnvalue=8\n",
    "elif default =='N':\n",
    "  limlength=int(input('limlength= (default value is 15)'))\n",
    "  maxlen=int(input('maxlen= (default value is 40)'))\n",
    "  genlevelcostmultiplier=float(input('genlevelcostmultiplier= (default value is 1.2)'))\n",
    "  minpatmultiplier= float(input('minpatmultiplier= (default value is 0.7)'))\n",
    "  acc_threshold= float(input('acc_threshold= (default value is 0.95)'))\n",
    "  lencomparison=int(input('lencomparison= (default value is 20)')) #this is to limit the number of comparisons made for the similarity measure to improve performance. only relevant for large number of long strings (otherwise doesn't run)\n",
    "  pvalue=float(input('pvalue= (default value is 0.05)'))\n",
    "  smallnfpvalue=float(input('smallnfpvalue= (default value is 1.5)'))\n",
    "  smallnfnvalue=float(input('smallnfnvalue= (default value is 8)'))\n",
    "main(limlength,maxlen,genlevelcostmultiplier, minpatmultiplier,acc_threshold,lencomparison,pvalue,smallnfpvalue, smallnfnvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXi2QC8wOwd8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
